---
title: "hazard example"
output:
  pdf_document: default
  html_document: default
date: "2024-01-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
```

# Assessment question

For this hazard identification the question is if exposure to compound $X$ can cause an effect in a chosen endpoint? This is a categorical questions with two possible answers NO and YES.

# Practical certainty

```{r}
pc_yes = 0.66
pc_no = 0.8
```

The practical certainty is by risk managers set to be `r pc_yes*100`\% probability for a YES and `r pc_no*100`\% probability for a NO. The assessment is *inconclusive* for any uncertainty in between the limits.

# A tiered approach with uncertainty expressed by a precise probability

## Step 1.1

Evidence is a QSAR with known sensitivity (TPR=80\%) and specificity (TNR=70\%) with a negative prediction for the endpoint.

> Sensitivity (true positive rate) is the probability of a positive test result, conditioned on the individual truly being positive.

> Specificity (true negative rate) is the probability of a negative test result, conditioned on the individual truly being negative.

```{r}
tpr = 0.8 
tnr = 0.7 
```

We (the assessors) apply Bayesian reasoning with a prior probability of 50\% (*As likely as not*) that the answer is YES to the assessment question.

```{r}
#prior
p_yes = 0.5 

#likelihood
lik_evid_pos = (1-tpr[1]) 
lik_evid_neg = tnr[1] 

#posterior for yes
post_yes =  lik_evid_pos*p_yes / (lik_evid_pos*p_yes + lik_evid_neg*(1-p_yes)) #Bayes rule
  
```

Given the evidence, the we are `r round(post_yes*100,0)`\% certain that $X$ is an hazard.

This is the same thing as saying that we are `r round((1-post_yes)*100,0)`\% certain that the answer is NO.

Is practical certainty reached?

No. 

We proceed by **reducing** uncertainty by collecting more information.

## Step 1.2

Evidence now consists of two more QSARs with known sensitivities and specificities

| TPR | TNR | Prediction |
|:---:|:---:|:----------:|
| 80% | 70% |  negative  |
| 75% | 90% |  negative  |
| 50% | 70% |  positive  |

```{r}
tpr = c(0.8,0.75,0.5) 
tnr = c(0.7,0.9,0.7) 
```

We (the assessors) apply Bayesian reasoning with a prior probability of 50\% that the answer is YES to the assessment question.

```{r}
# data
evid = c("neg","neg","pos")

# likelihood
lik_evid_pos_step2 = (1-tpr[1])*(1-tpr[2])*tpr[3]
lik_evid_neg_step2 = (tnr[1])*(tnr[2])*(1-tnr[3])
  
#posterior for yes
post_yes_step2 =  lik_evid_pos_step2*p_yes / (lik_evid_pos_step2*p_yes + lik_evid_neg_step2*(1-p_yes)) #Bayes rule
```

The probability of YES given the evidence is `r round(post_yes_step2*100,0)`\%

This is the same thing as the probability of NO given the evidence is `r round((1-post_yes_step2)*100,0)`\%

Is practical certainty reached?

Yes. 

## Conclusion 1

There is sufficient certainty that $X$ is not a hazard. Proceed with the decision.

# A tiered approach with uncertainty expressed by a bounded probability

## Step 2.1

Same as above, but start with a prior for a YES bounded in the range of inconclusiveness i.e. between `r (1-pc_no)*100` and `r pc_yes*100`\% probability.

```{r}
prior_yes_imp = seq(1-pc_no,pc_yes,by=0.01)

post_yes_imp =  lik_evid_pos*prior_yes_imp / (lik_evid_pos*prior_yes_imp + lik_evid_neg*(1-prior_yes_imp))
```

The probability of YES given the evidence is between `r round(min(post_yes_imp)*100,0)` and `r round(max(post_yes_imp)*100,0)`\%.

Is practical certainty reached?

No.

```{r, echo = FALSE}
  
mm = range(dnorm(qnorm(prior_yes_imp)))
second_order_measure = (dnorm(qnorm(prior_yes_imp))-mm[1])/(mm[2]-mm[1])*10
df <- data.frame(p_YES = c(prior_yes_imp,post_yes_imp), a = rep(second_order_measure,2), type = rep(c("prior","posterior"),each=length(prior_yes_imp)))

ind_low = min(which(post_yes_imp >= pc_yes),0)
ind_high = max(which(post_yes_imp <= (1-pc_no)),0)

#prior_yes_imp[ind_low]
#prior_yes_imp[ind_high]
```

The prior probability must be less than `r round(100*prior_yes_imp[ind_high],0)`\% instead of less than `r round(100*max(prior_yes_imp),0)`\% for the conclusion to reach practical certainty.

A way to illustrate this is to use an unit-less measure for second order uncertainty (or robustness) that maps the prior to the posterior. 
 
```{r, echo = FALSE}

ggplot2::ggplot(df,aes(x=p_YES,y=a, colour = type)) +
  geom_hline(
    aes(yintercept = y), 
    data.frame(y = c(2.5,5,7.5)),
    color = "lightgrey"
  ) +
  geom_vline(
    aes(xintercept = x), 
    data.frame(x = c(1-pc_no,pc_yes)),
    color = c("#269C2E","darkred")
  ) +
geom_line(aes(linetype=type)) + 
  scale_colour_manual(values = c("#2B308B", "#57B4ED")) +
  ylab("2nd order uncertainty") +
  xlab("% probability YES") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  scale_y_continuous(name="2nd order uncertainty", breaks=c(2.5,5,7.5), labels = c("","",""), limits = c(0,11)) +
  xlim(0,1) + 
  annotate(geom="text", x=(1-pc_no)/2, y=11, label="NO",
              color="#269C2E") +
  annotate(geom="text", x=(pc_yes + 1)/2, y=11, label="YES",
              color="darkred") +
  annotate(geom="text", x=(pc_yes + (1-pc_no))/2, y=11, label="INCONLUSIVE",
              color="black")  

```

Let us proceed by **reducing** uncertainty by collecting more information.

## Step 2.2

Same as above for step 2 with three QSARs.

```{r}
post_yes_imp_step2 =  lik_evid_pos_step2*prior_yes_imp / (lik_evid_pos_step2*prior_yes_imp + lik_evid_neg_step2*(1-prior_yes_imp))
```

The probability of YES given the evidence is between `r round(min(post_yes_imp)*100,0)` and `r round(max(post_yes_imp)*100,0)`\%.

Is practical certainty reached?

No, but it is close.

```{r, echo = FALSE}
df_step2 <- data.frame(p_YES = c(prior_yes_imp,post_yes_imp_step2), a = rep(second_order_measure,2), type = rep(c("prior","posterior"),each=length(prior_yes_imp)))

ind_low = min(which(post_yes_imp_step2 >= pc_yes),0)
ind_high = max(which(post_yes_imp_step2 <= (1-pc_no)),0)

#prior_yes_imp[ind_low]
#prior_yes_imp[ind_high]
```

The prior probability for a YES must be less than `r round(100*prior_yes_imp[ind_high],0)`\% instead of less than `r round(100*max(prior_yes_imp),0)`\% for the conclusion to reach practical certainty.


```{r, echo = FALSE}

ggplot2::ggplot(df_step2,aes(x=p_YES,y=a, colour = type)) +
  geom_hline(
    aes(yintercept = y), 
    data.frame(y = c(2.5,5,7.5)),
    color = "lightgrey"
  ) +
  geom_vline(
    aes(xintercept = x), 
    data.frame(x = c(1-pc_no,pc_yes)),
    color = c("#269C2E","darkred")
  ) +
geom_line(aes(linetype=type)) + 
  scale_colour_manual(values = c("#2B308B", "#57B4ED")) +
  ylab("2nd order uncertainty") +
  xlab("% probability YES") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  scale_y_continuous(name="2nd order uncertainty", breaks=c(2.5,5,7.5), labels = c("","",""), limits = c(0,11)) +
  xlim(0,1) + 
  annotate(geom="text", x=(1-pc_no)/2, y=11, label="NO",
              color="#269C2E") +
  annotate(geom="text", x=(pc_yes + 1)/2, y=11, label="YES",
              color="darkred") +
  annotate(geom="text", x=(pc_yes + (1-pc_no))/2, y=11, label="INCONLUSIVE",
              color="black")  

```


Let us proceed by **refining** the characterisation of uncertainty.

## Step 2.3 

The assessors agree that prior for a YES could have been less than 60\% probability.

This implies that practical certainty is reached. 

Risk managers agree that the conclusion is NO with sufficient certainty. 

## Conclusion 2

There is sufficient certainty that $X$ is not a hazard. Proceed with the decision.

# A tiered approach with uncertainty analysis done using DST
